
export function getDummyData() {
  return [
    {
      "id": 1,
      "first_author_name": "Smith, John",
      "title": "Advancements in Quantum Computing",
      "why": "Quantum computing has the potential to revolutionize computational capabilities. This study aims to explore recent breakthroughs and their implications.\n",
      "contribution": "This paper presents a novel approach to qubit stability, improving coherence times by 30%. We introduce a new error correction algorithm that significantly reduces decoherence. Our findings pave the way for more reliable quantum computations in various fields.\n",
      "related_works": "Previous studies by Johnson et al. (2022) and Lee (2023) addressed qubit coherence. Our work builds upon their findings and introduces innovations in error correction. We also compare our results with the recent quantum supremacy claims by major tech companies.\n"
    },
    {
      "id": 2,
      "first_author_name": "Garcia, Maria",
      "title": "The Impact of Social Media on Mental Health",
      "why": "With the increasing prevalence of social media, understanding its effects on mental health is crucial. This research aims to provide insights into both positive and negative impacts.\n",
      "contribution": "Our study presents a comprehensive meta-analysis of 50 recent studies on social media and mental health. We identify key factors that contribute to both positive and negative outcomes. The paper proposes a new framework for assessing social media's impact on different age groups. Our findings can inform policy-making and guide future research in this field.\n",
      "related_works": "We build upon the foundational work of Brown (2020) on social media addiction. Our study also incorporates recent findings from Chen et al. (2023) on the positive aspects of online communities. We contrast our results with the longitudinal study by Wilson (2022) on adolescent mental health.\n"
    },
    {
      "id": 3,
      "first_author_name": "Patel, Ravi",
      "title": "Sustainable Urban Planning: A Case Study of Singapore",
      "why": "Urban sustainability is a pressing global concern. Singapore's innovative approaches offer valuable insights for other rapidly developing cities.\n",
      "contribution": "This paper presents a detailed analysis of Singapore's sustainable urban planning strategies. We identify key success factors and potential areas for improvement. Our study proposes a transferable model for sustainable urban development. We also discuss the challenges of implementing similar strategies in different cultural contexts.\n",
      "related_works": "We expand on the urban sustainability framework proposed by Li et al. (2021). Our case study complements the comparative analysis of Asian cities by Yamamoto (2022). We also address criticisms raised in Thompson's (2023) paper on the limitations of Singapore's model.\n"
    },
    {
      "id": 4,
      "first_author_name": "Mueller, Anna",
      "title": "Artificial Intelligence in Early Cancer Detection",
      "why": "Early cancer detection significantly improves treatment outcomes. AI has the potential to enhance detection accuracy and speed, potentially saving numerous lives.\n",
      "contribution": "We present a new AI algorithm for analyzing medical imaging data to detect early-stage cancers. Our model demonstrates a 15% improvement in detection accuracy compared to current methods. We also address ethical considerations and propose guidelines for AI implementation in healthcare. The paper includes a cost-benefit analysis of widespread adoption of this technology.\n",
      "related_works": "Our work builds upon the pioneering AI-based detection system by Zhang et al. (2021). We address the limitations identified in the review by Alvarez (2022) on AI in oncology. Our ethical framework expands on the principles outlined in the WHO's 2023 report on AI in healthcare.\n"
    },
    {
      "id": 5,
      "first_author_name": "Okonkwo, Chioma",
      "title": "The Economic Impact of Climate Change on Sub-Saharan Agriculture",
      "why": "Climate change poses significant threats to agricultural sustainability in Sub-Saharan Africa. Understanding these impacts is crucial for developing effective adaptation strategies.\n",
      "contribution": "Our study provides a comprehensive economic analysis of climate change effects on key crops. We present projections for agricultural productivity and food security up to 2050. The paper proposes region-specific adaptation strategies and policy recommendations. We also introduce a new model for assessing the cost-effectiveness of various interventions.\n",
      "related_works": "We extend the climate impact models developed by Nkrumah (2022) for West African agriculture. Our economic projections build upon the work of Diop et al. (2023) on climate resilience. We also incorporate recent findings from the IPCC's 2024 special report on African food systems.\n"
    },
    {
      "id": 6,
      "first_author_name": "Tanaka, Hiro",
      "title": "Nanotechnology in Water Purification: Breakthroughs and Challenges",
      "why": "Access to clean water remains a global challenge. Nanotechnology offers promising solutions for efficient and cost-effective water purification.\n",
      "contribution": "This paper presents a novel nanocomposite material for removing heavy metals and organic pollutants. We demonstrate a 40% improvement in purification efficiency compared to conventional methods. Our study includes a scalability analysis and potential applications in both urban and rural settings. We also address the environmental impact and safety considerations of nanotech in water treatment.\n",
      "related_works": "Our nanocomposite design builds upon the groundbreaking work of Li and Patel (2022) on graphene oxides. We compare our results with the recent field trials by Waterworks International (2023) in Southeast Asia. Our environmental impact assessment expands on the framework proposed by Green et al. (2024).\n"
    },
    {
      "id": 7,
      "first_author_name": "Kowalski, Eva",
      "title": "The Neuroscience of Multilingualism: Cognitive Benefits and Challenges",
      "why": "As global interconnectedness increases, understanding the cognitive impacts of multilingualism becomes increasingly relevant for education and cognitive health.\n",
      "contribution": "Our study presents new fMRI data on brain activity patterns in multilingual individuals. We identify specific cognitive advantages associated with different types of multilingualism. The paper proposes a new model for understanding language acquisition in multilingual contexts. We also discuss implications for educational policies and cognitive decline prevention.\n",
      "related_works": "We build upon the seminal work of Chen and Rodriguez (2021) on bilingual cognitive advantages. Our findings complement the longitudinal study by Petersen et al. (2023) on language and aging. We also address recent criticisms by Smith (2024) regarding methodological issues in multilingualism research.\n"
    },
    {
      "id": 8,
      "first_author_name": "Al-Fayed, Amira",
      "title": "Renewable Energy Integration in Smart Cities: A Middle Eastern Perspective",
      "why": "Smart city development offers opportunities for sustainable energy solutions. The Middle East's unique climate and rapid urbanization present both challenges and opportunities in this field.\n",
      "contribution": "This paper presents a comprehensive analysis of renewable energy integration in Gulf Cooperation Council cities. We introduce a new model for optimizing solar and wind energy utilization in urban environments. Our study includes case studies of successful implementations and lessons learned. We also propose policy frameworks to accelerate renewable energy adoption in smart city development.\n",
      "related_works": "Our work extends the smart city energy models developed by Zhao et al. (2022) for arid climates. We build upon the policy analysis conducted by Al-Saud (2023) on Middle Eastern energy transitions. Our optimization model incorporates recent advances in urban wind energy as reported by Lee (2024).\n"
    },
    {
      "id": 9,
      "first_author_name": "Fernandez, Carlos",
      "title": "The Role of Gut Microbiota in Autoimmune Diseases",
      "why": "Autoimmune diseases are increasingly prevalent globally. Recent research suggests a significant link between gut microbiota and autoimmune responses.\n",
      "contribution": "Our study presents a comprehensive analysis of gut microbiome compositions in various autoimmune conditions. We identify specific bacterial strains associated with increased and decreased autoimmune activity. The paper proposes a new model for understanding the gut-immune system axis in autoimmune diseases. We also discuss potential therapeutic interventions based on microbiome modulation.\n",
      "related_works": "We expand on the microbiome profiling work of Kim et al. (2022) in rheumatoid arthritis patients. Our findings complement the recent meta-analysis by Johnson (2023) on diet and autoimmune diseases. We also address the controversies raised in Smith's (2024) critique of microbiome-based therapies.\n"
    },
    {
      "id": 10,
      "first_author_name": "Novak, Petra",
      "title": "Ethical Implications of Human Gene Editing: A Global Perspective",
      "why": "Advancements in CRISPR and related technologies have made human gene editing a reality. This raises profound ethical questions that require careful consideration and global dialogue.\n",
      "contribution": "This paper presents a comprehensive review of current gene editing technologies and their potential applications. We analyze ethical frameworks from various cultural and religious perspectives. The study proposes a new model for international governance of human gene editing research and applications. We also discuss the societal implications of gene editing, including issues of equity and access.\n",
      "related_works": "We build upon the ethical framework proposed by the WHO's 2022 report on human genome editing. Our cultural analysis expands on the comparative study by Chen et al. (2023) on Eastern and Western bioethics. We also address recent developments and controversies as outlined in the 2024 International Summit on Human Genome Editing."
    }
  ]
}

export function getDummyChatHistory() {
  return [
    {
      "is_assistant": false,
      "message": "I've heard about large language models like GPT-2 being used for text generation. Are there any recent advancements in generating longer, more coherent passages of text?"
    },
    {
      "is_assistant": true,
      "message": "Yes, there have been recent advancements in generating longer, more coherent passages of text. Researchers have developed a new method that addresses some limitations of large language models like GPT-2, especially when it comes to generating long-form content (around 1000 tokens) in specific domains with limited training data.\n\nThis new approach uses a progressive generation technique, inspired by image generation methods that start from low to high resolution. The process involves multiple stages:\n\n1. First, it produces domain-specific content keywords.\n2. Then, it progressively refines these keywords into complete passages over several stages.\n\nThis method has shown significant improvements over fine-tuned large language models and other planning-then-generation approaches in terms of both quality and sample efficiency. It's particularly effective when adapting to target domains with only a small set of examples, which is a common challenge in real-world applications."
    },
    {
      "is_assistant": false,
      "message": "That sounds interesting! How does this progressive generation method compare to traditional approaches in terms of coherence and overall quality of the generated text?"
    },
    {
      "is_assistant": true,
      "message": "The progressive generation method has shown notable improvements in coherence and overall quality compared to traditional approaches. Here are some key points:\n\n1. Coherence: The study conducted a comprehensive empirical evaluation using a broad set of metrics. The results indicated that this new method produces more coherent long passages of text compared to fine-tuned large language models and various planning-then-generation methods.\n\n2. Human evaluation: Importantly, human evaluators also confirmed that the text generated by this progressive method is more coherent than that produced by traditional approaches.\n\n3. Adaptability: The method is particularly effective at adapting to specific target domains, even when only a small set of examples is available for fine-tuning. This is a significant advantage over traditional methods that often struggle with domain-specific generation when training data is limited.\n\n4. Quality across domains: The approach has demonstrated improvements in generating long-form content across various domains, suggesting its versatility and robustness.\n\n5. Sample efficiency: The study noted that this method is more sample-efficient, meaning it can produce higher quality outputs with less training data compared to traditional approaches.\n\nOverall, while large language models like GPT-2 are powerful open-domain text generators, this progressive generation method addresses some of their limitations, particularly in generating coherent, domain-specific long passages of text."
    }
  ]
}

// export function getDummyChatHistory() {
//   return [
//     {
//       "is_assistant": false,
//       "message": "Quick update: The meeting has been rescheduled for tomorrow at 3 PM."
//     },
//     {
//       "is_assistant": true,
//       "message": "Here's a detailed summary of the project's current status. We have completed the initial design phase, and feedback from the testing team has been largely positive. However, there are concerns about the integration with the legacy system, which could potentially delay the next phase. The development team is currently evaluating solutions and will present their findings in the upcoming meeting. Let's ensure all stakeholders are kept in the loop to avoid any surprises."
//     },
//     {
//       "is_assistant": false,
//       "message": "Remember to submit your timesheets by Friday!"
//     },
//     {
//       "is_assistant": true,
//       "message": "I have compiled the data for last month's sales report. It appears that our new marketing strategy is working, as there is a noticeable increase in customer engagement across all platforms. This should positively impact our revenue this quarter."
//     },
//     {
//       "is_assistant": false,
//       "message": "Lunch at noon? Let's try the new Italian place."
//     },
//     {
//       "is_assistant": true,
//       "message": "As part of our ongoing commitment to improve workflow efficiency, I have scheduled a training session for next week. This session will focus on the new software tools that were recently integrated into our systems. Attendance is crucial for all team members as it will greatly benefit our project's timeline."
//     }
//   ]
// }

export function getDummySuggestions() {
  //   return {
  //   "suggestions": [
  //     "Thanks for the update! I'll adjust my schedule accordingly.",
  //     "Thanks for the reminder! I'll make sure my timesheets are in by tomorrow.",
  //     "Sounds good! I've been wanting to try that place. See you at noon."
  //   ]
  // }
  return [
    {"suggestion": "Thanks for the update! I'll adjust my schedule accordingly."},
    {"suggestion": "Thanks for the reminder! I'll make sure my timesheets are in by tomorrow."},
    {"suggestion": "Sounds good! I've been wanting to try that place. See you at noon."}
  ]
}

export function sendMessage() {
  // send message to backend
  return true;
}

export function getMindmap() {
  return `* **Retrieval-Augmented Generation (RAG)**
    - **Goal:** Identify optimal RAG practices for enhancing LLM performance and reliability.
    - **Workflow:**
        - **Query Classification:** Determine retrieval necessity based on task type.
            * **Methods:**
                - BERT-based classifier trained on Dolly-15K and GPT-4 generated data.
        - **Chunking:** Divide documents into segments for efficient retrieval.
            * **Methods:**
                - Sentence-level chunking.
                - **Chunk Size:** Balance context preservation and processing time.
                - **Chunking Techniques:** Small-to-big and sliding window for context maintenance.
                - **Embedding Model Selection:** LLM-Embedder for performance and size balance.
                - **Metadata Addition:** Enhance retrieval with titles, keywords, etc. (future work).
        - **Vector Databases:** Efficiently store and retrieve document embeddings.
            * **Methods:**
                - **Milvus:** Best choice based on multiple index types, billion-scale vector support, hybrid search, and cloud-native capabilities.
        - **Retrieval Methods:** Select relevant documents based on query similarity.
            * **Methods:**
                - **Hybrid Search with HyDE:** Combines sparse (BM25) and dense (LLM-Embedder) retrieval with hypothetical document generation.
                - **Query Rewriting:** Refine queries for better matching.
                - **Query Decomposition:** Retrieve based on sub-questions.
                - **Pseudo-documents Generation:** Generate hypothetical documents for retrieval.
        - **Reranking Methods:** Improve relevance of retrieved documents.
            * **Methods:**
                - **DLM Reranking:** Utilize deep language models for classification-based reranking.
                    * **MonoT5:** Best choice balancing performance and efficiency.
                    * **MonoBERT:** High performance.
                    * **RankLLaMA:** Highest performance.
                - **TILDE Reranking:** Efficient reranking based on query likelihoods.
                    * **TILDEv2:** Fastest option.
        - **Document Repacking:** Arrange retrieved documents for optimal generation.
            * **Methods:**
                - **Reverse:** Arrange documents in ascending relevancy order (best choice).
                - **Forward:** Arrange documents in descending relevancy order.
                - **Sides:** Place relevant context at the head or tail of the input.
        - **Summarization:** Extract key information from retrieved documents.
            * **Methods:**
                - **Recomp:** Best choice, with both extractive and abstractive compressors.
                - **LongLLMLingua:** Alternative method with better generalization capability.
                - **Selective Context:** Non-query-based method for removing redundancy (not recommended).
        - **Generator Fine-tuning:** Optimize the generator for efficient use of context.
            * **Methods:**
                - **Dg:** Fine-tuning with only relevant documents.
                - **Dr:** Fine-tuning with randomly sampled documents.
                - **Dgr:** Fine-tuning with both relevant and random documents (best choice).
                - **Dgg:** Fine-tuning with two copies of a relevant document.
    - **Best Practices:**
        - **Best Performance Practice:** Query classification, Hybrid Search with HyDE, MonoT5, Reverse, Recomp.
        - **Balanced Efficiency Practice:** Query classification, Hybrid Search, TILDEv2, Reverse, Recomp.
    - **Multimodal Extension:**
        - **Text2Image Retrieval:** Speed up image generation using image captions.
        - **Image2Text Retrieval:** Utilize image-text pairs for conversational image understanding.
        - **Benefits:** Groundedness, efficiency, maintainability.
    - **Evaluation:**
        - **Comprehensive Evaluation:**
            * **Tasks:** Commonsense Reasoning, Fact Checking, Open-Domain QA, MultiHop QA, Medical QA.
            * **Metrics:** Accuracy, F1 score, EM score, RAG capabilities (Faithfulness, Context Relevancy, Answer Relevancy, Answer Correctness), Retrieval Similarity.
            - **Datasets:** MMLU, ARC-Challenge, OpenbookQA, FEVER, PubHealth, NQ, TriviaQA, WebQuestions, HotpotQA, 2WikiMultiHopQA, MuSiQue, PubMedQA.
        - **Results:**
            * Each module contributes to overall performance.
            * Query classification enhances accuracy and reduces latency.
            * Retrieval and reranking improve handling of diverse queries.
            * Repacking and summarization refine output quality.
    - **Limitations:**
        - Joint training of retriever and generator (future work).
        - Limited exploration of chunking techniques due to resource constraints.
        - Future expansion to other modalities (speech, video).`
}


export function getDummyCode() {
  return String.raw`# ===
# This code was generated by an AI and should be reviewed before running.
# ===

# ===
# Imports
# ===
from transformers import pipeline
import networkx as nx

# ===
# Constants
# ===
K_HOPS = 2
MAX_NEIGHBORS = 5

# ===
# Utils
# ===
def generate_subgraph(kg, entity, k_hops, max_neighbors):
    """Simulates retrieving a subgraph from a knowledge graph."""
    # Placeholder implementation for demonstration purposes
    subgraph = nx.ego_graph(kg, entity, radius=k_hops)
    return subgraph

def aggregate_subgraphs(subgraphs):
    """Aggregates subgraphs into a simplified 'Mind Map' string."""
    # Placeholder implementation
    mind_map = "Mind Map:\n"
    for i, subgraph in enumerate(subgraphs):
        mind_map += f"Subgraph {i+1}:\n"
        for u, v, data in subgraph.edges(data=True):
            mind_map += f"- {u} -- {data.get('relation', '')} --> {v}\n"
    return mind_map

def generate_prompt(question, mind_map):
    """Constructs a prompt incorporating the question and mind map."""
    prompt = f"Question: {question}\n{mind_map}\nAnswer:"
    return prompt

# ===
# Main
# ===
if __name__ == '__main__':
    # Toy Knowledge Graph
    kg = nx.Graph()
    kg.add_edge("Python", "Programming Language", relation="is a")
    kg.add_edge("Python", "Popular", relation="is")
    kg.add_edge("Programming Language", "Used for", relation="is")
    kg.add_edge("Used for", "Software Development", relation="")

    # Sample Question and Entity
    question = "What is Python used for?"
    entity = "Python"

    # Generate Subgraphs
    subgraphs = [generate_subgraph(kg, entity, K_HOPS, MAX_NEIGHBORS)]

    # Aggregate Subgraphs into Mind Map
    mind_map = aggregate_subgraphs(subgraphs)

    # Construct Prompt
    prompt = generate_prompt(question, mind_map)

    # Print the generated prompt
    print(prompt)`
}


// ===
// Actual API
// ===
import axios from 'axios';

const localApiUrl = 'http://localhost:8080';

export const getMindmapMd = async (url) => {
  try {
    const response = await axios.get(`${localApiUrl}/mindmap_md`, {
      params: { url: url },
    });
    return response.data;
  } catch (error) {
    console.error('Error fetching mindmap:', error);
    throw error;
  }
};

export const generateCode = async (mindmap) => {
  try {
    const response = await axios.post(`${localApiUrl}/code`, {
      mindmap: mindmap
    }, {
      headers: {
        'Content-Type': 'application/json'
      }
    });
    
    return response.data.code;
  } catch (error) {
    console.error('Error generating code:', error);
    throw error;
  }
};


// Mihir's API
const apiUrl = 'https://c4f1-73-126-64-43.ngrok-free.app'; // Adjust this URL as needed

// Function to get summaries
export const getSummaries = async (paperUrl) => {
  console.log('Fetching summaries for:', paperUrl);
  try {
    const response = await axios.post(`${apiUrl}/get_summaries`, {
      paper_url: paperUrl
    });
    console.log('Response:')
    console.log(response.data);
    return convertJsonFormat(response.data);
  } catch (error) {
    console.error('Error getting summaries:', error);
    throw error;
  }
};
function convertJsonFormat(inputJson) {
  const { summary, qa_for_references } = inputJson;
  
  let output = [];
  let id = 1;

  for (const [key, value] of Object.entries(qa_for_references)) {
    for (const [refKey, refValue] of Object.entries(value)) {
      const { qa_pairs, paper_data } = refValue;
      
      output.push({
        id: parseInt(refKey.slice(1)) + 1,
        first_author_name: paper_data.first_author,
        title: paper_data.title,
        why: qa_pairs["How does this reference support the current paper's hypothesis or main argument?\nWhat you should focus on while answering: Understanding the role of the reference in supporting the main points of the research paper is crucial. Does it provide foundational theories, corroborate findings, or offer contrasting views that are addressed within the paper?"],
        contribution: qa_pairs["What methodologies or key findings from the referenced work are relevant to the current study?\nWhat you should focus on while answering : Identifying specific methodologies or findings that are referenced can shed light on the research design, analysis, and conclusions of the current paper. It helps in understanding how the referenced work influences or relates to the study at hand."],
        related_works: qa_pairs["What is the significance of the referenced work in the field, and how current is it?\nWhat you should focus on while answering: Evaluating the relevance and impact of the referenced work helps in understanding its importance. Consider the publication date, the reputation of the authors, and how frequently the work has been cited by other scholars."]
      });

      id++;
    }
  }

  return output;
}

// Function to get chat response
export const getChatResponse = async (paperUrl, history, newMessage) => {
  try {
    history = jsonToChat(history);
    const response = await axios.post(`${apiUrl}/get_chat_response`, {
      paper_url: paperUrl,
      history: history,
      new_message: `User: ${newMessage}`
    });
    return response.data;
  } catch (error) {
    console.error('Error getting chat response:', error);
    throw error;
  }
};

function jsonToChat(jsonData) {
  let chatString = '';
  
  jsonData.forEach(entry => {
    const speaker = entry.is_assistant ? 'Assistant' : 'User';
    chatString += `${speaker}: ${entry.message}\n\n`;
  });
  
  return chatString.trim();
}